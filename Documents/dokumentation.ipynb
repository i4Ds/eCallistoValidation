{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eCallisto Validation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Das Ziel dieses Pakets ist:\n",
    "\n",
    "1) Anhängen die Metadaten an die Datenbank(save_to_sql.py).\n",
    "* Metadaten sind definiert als Daten, die Informationen über einen oder mehrere Aspekte der Daten liefern; Es wird verwendet, um grundlegende Informationen über Daten zusammenzufassen.\n",
    "* Datenbank ist eine organisierte Sammlung strukturierter Informationen oder Daten, die normalerweise elektronisch in einem Computersystem gespeichert werden\n",
    "\n",
    "2) Berechnen die Standardabweichung und upadte in die Datenbank (STD.py).\n",
    "* Was ist die Standardabweichung? Die Standardabweichung ist die durchschnittliche Variabilität in Ihrem Datensatz.Es sagt im Durchschnitt, wie weit jede Punktzahl vom Mittelwert entfernt ist. Eine hohe Standardabweichung bedeutet, dass die Werte in Normalverteilungen im Allgemeinen weit vom Mittelwert entfernt sind, während eine niedrige Standardabweichung anzeigt, dass die Werte nahe am Mittelwert geclustert sind.\n",
    "\n",
    "3) Wählen 10 Spectrograms pro Station und Plotten sie mit 4 Spalten, dann speichern sie als PDF-Datei(Testing_10000.py).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importieren der Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import sys\n",
    "import astropy.io.fits\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import time\n",
    "import timeit\n",
    "import skimage.transform\n",
    "import psycopg2.extras\n",
    "import psycopg2\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import pandas as pd\n",
    "import pandas.io.sql as psql\n",
    "from sqlalchemy import create_engine\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "sys.path.append(os.path.join(os.path.dirname(__file__), \"..\", \"radiospectra\"))\n",
    "module_path = os.path.abspath(os.path.join('radiospectra'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "\n",
    "import radiospectra\n",
    "from radiospectra.sources import CallistoSpectrogram\n",
    "\n",
    "from matplotlib.backends.backend_pdf import PdfPages, FigureCanvasPdf, PdfFile\n",
    "import datetime\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Der Weg zu den Daten in meinem Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'R:\\\\radio\\\\2002-20yy_Callisto\\\\2017\\\\09'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save_to_sql.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Umrechnen der Zeit(von Kushtrim)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __to_timestamp(date_string, time_string):\n",
    "    \n",
    "                sixty_seconds = int(time_string[6:8]) == 60\n",
    "                sixty_minutes = int(time_string[3:5]) == 60\n",
    "                twentyfour_hours = int(time_string[:2]) == 24\n",
    "                \n",
    "                # replacing  24 to 00 \n",
    "                if sixty_seconds :\n",
    "                    time_string = time_string[:6] + '59' + time_string[8:]\n",
    "                if sixty_minutes :\n",
    "                    time_string = time_string[:3] + '59' + time_string[5:]\n",
    "                if twentyfour_hours :\n",
    "                    time_string = '23' + time_string[2:]\n",
    "                if re.findall(\"\\.\\d+\", time_string):\n",
    "                    time_string = time_string[:-4]\n",
    "                    \n",
    "                # lost time     \n",
    "                ts = datetime.datetime.strptime(\n",
    "                    '%s %s' % (date_string, time_string), '%Y/%m/%d %H:%M:%S')                  \n",
    "                ts += datetime.timedelta(hours = int(twentyfour_hours),\n",
    "                                         minutes = int(sixty_minutes),\n",
    "                                         seconds = int(sixty_seconds))\n",
    "                \n",
    "                return ts  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Stellen eine DBAPI-Verbindung unter localhost:5432 her, wenn eine Verbindungsanforderung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_engine():\n",
    "    global engine\n",
    "    engine = create_engine(\n",
    "        \"postgresql+psycopg2://\" + 'postgres' + \":\" + 'ecallistohackorange' + \"@\" + 'localhost' + \"/\" + 'validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Das Ziel dieses Skripts ist:\n",
    "* Gehen in den Pfad entlang, um die Daten zu finden.\n",
    "* Öffnen die Fits-Datei aus der Header-Liste (hdulist).\n",
    "* Rufen die Metadaten aus der Header-Liste (hdulist) auf. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_metaData():\n",
    "    df = 0\n",
    "\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for name in files:\n",
    "            if name.endswith('.fit.gz'):\n",
    "                full_path = os.path.join(root, name)\n",
    "\n",
    "                hdulist = astropy.io.fits.open(full_path)\n",
    "                split_path = full_path.split(\"Callisto/\")\n",
    "\n",
    "                instrument_name = hdulist[0].header['INSTRUME']\n",
    "                date_obs = hdulist[0].header['DATE-OBS']\n",
    "                time_obs = hdulist[0].header['TIME-OBS']\n",
    "                date_end = hdulist[0].header['DATE-END']\n",
    "                time_end = hdulist[0].header['TIME-END']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Kombinieren \"date and time obs, date and time end\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine date and time obs, date and time end\n",
    "start_time = __to_timestamp(date_obs, time_obs)\n",
    "end_time = __to_timestamp(date_end, time_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In diesem Skript :\n",
    "* Erstellen eines Datenrahmens in Pandas.\n",
    "* Einfügen der Daten in den Datenrahmen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "- creating dataframe in pandas\n",
    "- Inserting the data into the DataFrame\n",
    "\"\"\"\n",
    "\n",
    "data = {\n",
    "    'path': [split_path[1]],\n",
    "    'file_name': [name],\n",
    "    'instrument_name': [instrument_name],\n",
    "    'start_time': [start_time],\n",
    "    'end_time': [end_time],\n",
    "    'std': [None]\n",
    "}\n",
    "\n",
    "data_frame = pd.DataFrame(data, index=[df])\n",
    "\n",
    "# connection between pandas and sql\n",
    "data_frame.to_sql('data', con=engine,\n",
    "                  if_exists='append', chunksize=10000000, index=False)\n",
    "\n",
    "df = df + 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Erstellen eine Verbindung zwischen Pandas und SQL und dann hängen den Datenrahmen an SQL an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame.to_sql('validation_data', con = engine, if_exists = 'append',\n",
    "                  chunksize = 500000, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## update.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Wählen aus der Tabelle \"validation_data\",  um die Standardabweichung zu berechnen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Return a table from DB where the std is null\"\"\"\n",
    "\n",
    "cursor.execute(\"\"\"SELECT * from  validation_data WHERE std is null ORDER BY id\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Subtrahiere den Hintergrund.\n",
    "* Berechnen die Standardabweichung(std).\n",
    "* Update die berechnete Standardabweichung in die Tabelle ecallisto.\n",
    "* Exception, um alle Fehler zu zeigen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "- [1] is the index of file_name in the cursor.\n",
    "- subtract the background and then calculate the std.\n",
    "- update the std into the Database ecallisto\n",
    "- expetion to catch the all errors and append them into the List_of_err to check the erros.\n",
    "- close the connection\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"Return a list of STD and then update them into the DB\"\"\"\n",
    "\n",
    "for row in rows:\n",
    "        try:\n",
    "            spec = CallistoSpectrogram.read(test_config.DATA_PATH + row[1])\n",
    "\n",
    "            spec2 = spec.subtract_bg(\"subtract_bg_sliding_window\", window_width=800, affected_width=1,\n",
    "                                     amount=0.05, change_points=True)\n",
    "\n",
    "            data = np.absolute(spec2.data.flatten())\n",
    "            std_data = standard_deviation(data)\n",
    "            snr_data = signal_to_noise(data)\n",
    "\n",
    "            sql_update_query = f\"\"\"UPDATE data SET std = {std_data}, snr= {snr_data} where id = {row[0]} \"\"\"\n",
    "            cursor.execute(sql_update_query)\n",
    "            database.commit()\n",
    "\n",
    "        except Exception as err:\n",
    "            print(f\"The Error message is: {err} and the file name is {row[2]}\")\n",
    "            \n",
    "        finally:\n",
    "            print(\"Update Done!\")\n",
    "            database.close()\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spec_plot.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Die Verbindung mit der Datenbank.\n",
    "* Auswahl alle daten von Validation_data Tabelle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = psycopg2.connect(host=test_config.DB_HOST,\n",
    "                            user=test_config.DB_USER,\n",
    "                            database=test_config.DB_DATABASE,\n",
    "                            port=test_config.DB_PORT,\n",
    "                            password=test_config.DB_PASSWORD)\n",
    "\n",
    "sql_query = \"select * from validation_data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Um alle Daten aus der Datenbank zu bekommen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_instruments(database, sql_query):\n",
    "    \"\"\"\n",
    "    Get the all instruments from the Database\n",
    "    Parameters\n",
    "    ----------\n",
    "    database : a database 'Validation'.\n",
    "    sql_query: a query of sql to execute the script.\n",
    "    Returns\n",
    "    -------\n",
    "    index : index of the cursor from database.\n",
    "    \"\"\"\n",
    "\n",
    "    sql_query_instruments = sql_query\n",
    "    cursor = database.cursor(cursor_factory=psycopg2.extras.DictCursor)\n",
    "    cursor.execute(sql_query_instruments)\n",
    "    index = [row for row in cursor.fetchall()]\n",
    "\n",
    "    return index\n",
    "\n",
    "\n",
    "rows = get_all_instruments(database, sql_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Die erste Spalte enthält die Originaldaten (Spektrogramm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = CallistoSpectrogram.read(test_config.DATA_PATH + row[1])\n",
    "fig1, axs1 = plt.subplots(1, 4, figsize=(27, 6))\n",
    "ax1 = spec.plot()\n",
    "ax1.title.set_text(\"Original Data\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Die zweite Spalte enthält \"Background subtracted\" (von Kushtrim)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second column, Constbacksub + elimwrongchannels\n",
    "spec2 = spec.subtract_bg(\"constbacksub\", \"elimwrongchannels\")\n",
    "fig2 = plt.subplots(1, 4, figsize=(27, 6))\n",
    "ax2 = spec2.plot()\n",
    "ax2.title.set_text(\"Background subtracted\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Die dritte Spalte enthält 'Gliding background subtracted' (von Simon)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec3 = spec.subtract_bg(\"subtract_bg_sliding_window\", window_width=800, affected_width=1,\n",
    "                                 amount=0.05, change_points=True)\n",
    "fig3 = plt.figure(figsize=(27, 6))\n",
    "ax3 = spec3.plot()\n",
    "ax3.title.set_text(\"Gliding background subtracted (window=800)\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Die vierte Spalte enthält die Histogramme von \"Background subtracted\" and \"Gliding background subtracted (window=800)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fourth column, Histograms\n",
    "fig4, ax4 = plt.subplots(figsize=(27, 6))\n",
    "\n",
    "# Fourth column, Histograms\n",
    "data_absolute3 = get_abs_data(spec2)\n",
    "data_absolute4 = get_abs_data(spec3)\n",
    "\n",
    "# take the min and max from the data to set the bins.\n",
    "min_value = get_min_data(data_absolute3, data_absolute4)\n",
    "max_value = get_max_data(data_absolute3, data_absolute4)\n",
    "\n",
    "ax4.hist(data_absolute3, histtype='step', bins=range(\n",
    "    min_value, max_value + 1), label='Background subtracted')\n",
    "ax4.hist(data_absolute4, histtype='step', bins=range(\n",
    "    min_value, max_value + 1), label='Gliding background subtracted')\n",
    "\n",
    "# Calculate the standard deviation and signal-to-noise => rounded them to have 3 digits.\n",
    "std_data = round(np.std(data_absolute4), 3)\n",
    "snr_data = round(signal_to_noise(data_absolute4), 3)\n",
    "\n",
    "# Set title for the histograms and show the std/snr values.\n",
    "ax4.title.set_text(\n",
    "    f\"Histograms, std = {std_data}, snr = {snr_data}\")\n",
    "plt.legend()\n",
    "plt.close()\n",
    "\n",
    "# Plot final plot by moving axes to the figure\n",
    "fig_target, (axA, axB, axC, axD) = plt.subplots(\n",
    "    1, 4, figsize=(30, 9))\n",
    "plt.suptitle(fig1._suptitle.get_text())\n",
    "\n",
    "move_axes(fig_target, ax1, axA)\n",
    "move_axes(fig_target, ax2, axB)\n",
    "move_axes(fig_target, ax3, axC)\n",
    "move_axes(fig_target, ax4, axD)\n",
    "\n",
    "for ax in (ax1, ax2, ax3):\n",
    "    ax.set_xlabel('Time[UT]')\n",
    "    ax.set_ylabel('Frequency[MHz]')\n",
    "\n",
    "ax4.set_xlabel('Pixel values')\n",
    "ax4.set_ylabel('Number of pixels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Plotten den endgültigen Plot, indem die Achsen zur Figur veschieben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_target, (axA, axB, axC, axD) = plt.subplots(1, 4, figsize=(30,5))\n",
    "plt.suptitle(fig1._suptitle.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Die Achsen bewegen von Kushtrim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_axes(fig_target, ax1, axA)\n",
    "move_axes(fig_target, ax2, axB)\n",
    "move_axes(fig_target, ax3, axC)\n",
    "move_axes(fig_target, ax4, axD)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* To know the files with errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "except Exception as err:\n",
    "\n",
    "    print(f\"The Error message is: {err} and the file name is {row[2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Das Ziel dieses Skripts ist es, eine PDF-Datei mit mehreren Seiten zu erstellen sowie die Plotten und Histogramme zu PDF-Dateien hinzuzufügen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with PdfPages('Plot_PDF.pdf') as pdf:\n",
    "        pdf.savefig(fig_target)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## packages:\n",
    "\n",
    "* config.py\n",
    "* main.py\n",
    "* modules.py\n",
    "* requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### config.py :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Enthält die Daten des absolute Path und der Datenbanken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "PATH_PREFIX = '/data'\n",
    "DATA_PATH = os.path.join(PATH_PREFIX, 'radio/2002-20yy_Callisto')\n",
    "\n",
    "\n",
    "\n",
    "# database\n",
    "\n",
    "DB_HOST = 'localhost'\n",
    "DB_DATABASE = 'validation'\n",
    "DB_USER = 'postgres'\n",
    "DB_PASSWORD = 'ecallistohackorange'\n",
    "DB_PORT = '5432' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### main.py :\n",
    "* Enthält alle Functionen für den File spec_plot.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def signal_to_noise(arr):\n",
    "    \"\"\"Calculate the signal-to-noise ratio of the input data.\n",
    "    :param array_like arr: an array_like object contain the data.\n",
    "    :returns: The signal-to-noise ratio of {Arr}, here defined as the mean divided by the standard deviation.\n",
    "    :rtype: float\n",
    "    \"\"\"\n",
    "\n",
    "    m = arr.mean()\n",
    "    std = arr.std()\n",
    "    return m / std\n",
    "\n",
    "\n",
    "def get_abs_data(arr):\n",
    "    \"\"\"Get the absolute values from the arrays.\n",
    "    :param float arr: the data in the arrays from the spectrograms.\n",
    "    :returns: Return an array with absolute values.\n",
    "    :rtype: float.\n",
    "    \"\"\"\n",
    "    abs_data = np.absolute(arr.data.flatten())\n",
    "    return abs_data\n",
    "\n",
    "\n",
    "def get_min_data(data1, data2):\n",
    "    \"\"\"Get the minimum value from the both data1 and data2.\n",
    "    :param float * data1 : the data from spectrogram using the function 'Constbacksub + elimwrongchannels'\n",
    "    :param float * data2 : the data from spectrogram using the function  'subtract_bg_sliding_window'\n",
    "    :returns: Return the minimum values from data1, data2\n",
    "    :rtype: float.\n",
    "    \"\"\"\n",
    "    min_value = int(min(np.nanmin(data1), np.nanmin(data2)))\n",
    "    return min_value\n",
    "\n",
    "\n",
    "def get_max_data(data1, data2):\n",
    "    \"\"\"Get the maximum value from the both data1 and data2.\n",
    "     :param float data1 : the data from spectrogram using the function 'Constbacksub + elimwrongchannels'\n",
    "     :param float data2 : the data from spectrogram using the function  'subtract_bg_sliding_window'\n",
    "     :returns: Return the maximum values from data1, data2\n",
    "     :rtype: float.\n",
    "     \"\"\"\n",
    "    max_value = int(max(np.nanmax(data1), np.nanmax(data2)))\n",
    "    return max_value\n",
    "\n",
    "\n",
    "def move_axes(fig, ax_source, ax_target):\n",
    "    \"\"\" To move the axes to create a new Figure. \"\"\"\n",
    "    \n",
    "    old_fig = ax_source.figure\n",
    "    ax_source.remove()\n",
    "    ax_source.figure = fig\n",
    "    ax_source.set_ylabel('')\n",
    "    ax_source.set_xlabel('')\n",
    "\n",
    "    ax_source.set_position(ax_target.get_position())\n",
    "    ax_target.remove()\n",
    "    ax_target.set_aspect(\"equal\")\n",
    "    fig.axes.append(ax_source)\n",
    "    fig.add_subplot(ax_source)\n",
    "\n",
    "    plt.close(old_fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### requirements.txt :\n",
    "* Enthält alle Module und Pakete, die für die Skripte importiert werden müssen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "astropy~=4.2.1\n",
    "bs4~=0.0.1\n",
    "connexion\n",
    "flask\n",
    "flask_compress\n",
    "flask_cors\n",
    "iso8601\n",
    "numpy~=1.20.3\n",
    "psycopg2~=2.9.1\n",
    "Pillow~=8.2.0\n",
    "ruptures~=1.1.3\n",
    "scikit-image~=0.18.1\n",
    "scipy~=1.7.1\n",
    "sortedcontainers~=2.3.0\n",
    "sunpy~=2.1.5\n",
    "pandas~=1.3.2\n",
    "matplotlib~=3.4.2\n",
    "sqlalchemy~=1.4.23\n",
    "setuptools~=56.2.0\n",
    "beautifulsoup4~=4.9.3\n",
    "PIL\n",
    "pandas.io.sql\n",
    "re\n",
    "matplotlib.backends.backend_pdf\n",
    "os\n",
    "glob\n",
    "sys\n",
    "astropy.io.fits"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
